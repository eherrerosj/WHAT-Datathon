{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stackEnsemble\n",
    "\n",
    "The stackEnsemble function implements the technique of stack ensembling; the practice of using 1st level models to predict on the trainset (out of folds). These models are used to create predictions on the entire testset. This yields 'meta-features', and can be used as features for 2nd level models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports for predictive models and validation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# imports for stackEnsemble()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X = pd.read_csv('../../VIVAT2/data/X_categ.csv').reset_index()\n",
    "y = pd.read_csv('../../VIVAT2/data/y_categ.csv').reset_index().drop('index', axis=1)\n",
    "    \n",
    "# Split the data in test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# This is some random shit, i dont even \n",
    "# think you need that for every dataset\n",
    "X_train = X_train.reset_index().drop(['level_0', 'index'], axis=1)\n",
    "y_train = y_train.reset_index().drop('index', axis=1)\n",
    "X_test = X_test.reset_index().drop(['level_0', 'index'], axis=1)\n",
    "y_test = y_test.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' Function to perform stack ensembling on arbitrary dataset with sklearn models.\n",
    "\n",
    "# Arguments:\n",
    "    models:  list, a list of models to be used to create meta-features\n",
    "    X:       dataframe, the trainset features\n",
    "    y:       dataframe, the trainset labels\n",
    "    Xtest:   dataframe, the testset features\n",
    "    splits:  int, the number of splits for trainset CV\n",
    "    verbose: bool, true when print outputs are desired\n",
    "    \n",
    "# Returns:\n",
    "    X:       dataframe, new trainset with meta-features\n",
    "    Xtest:   dataframe, new testset with meta-features\n",
    "'''\n",
    "\n",
    "def stackEnsemble(models, X, y, Xtest, splits, verbose):\n",
    "\n",
    "    # assert correct data-types \n",
    "    assert type(models) == list\n",
    "    assert type(splits) == int\n",
    "    assert type(verbose) == bool\n",
    "\n",
    "    # init variables\n",
    "    kf = KFold(n_splits = splits)\n",
    "    predsTR = {}\n",
    "    predsTE = {}\n",
    "\n",
    "    # iterate over all inserted models\n",
    "    for n, model in enumerate(models):\n",
    "        if verbose: print('Using model %d to make predictions..' % (n+1))\n",
    "\n",
    "        # prepare split for predictions\n",
    "        predsTR['model'+str(n+1)] = []\n",
    "        for i, (train, test) in enumerate(kf.split(X)):\n",
    "            if verbose: print('..on split %d' % (i+1))\n",
    "\n",
    "            # fit on split and predict\n",
    "            model.fit(X.iloc[train], y.iloc[train])\n",
    "            predsTR['model'+str(n+1)].append(list(model.predict(X.iloc[test])))\n",
    "\n",
    "        # predict on testset\n",
    "        predsTE['model'+str(n+1)] = list(model.predict(Xtest))\n",
    "    \n",
    "    # combine trainset predictions in dataframe, join with trainset\n",
    "    meta_feats = pd.DataFrame(columns = [col for col in predsTR.keys()])\n",
    "    for model in predsTR.keys():\n",
    "        meta_feats[model] = np.array([item for lst in predsTR[model] for item in lst])\n",
    "    X = pd.concat([X, meta_feats], axis=1)\n",
    "\n",
    "    # combine testset predictions in dataframe, join with testset\n",
    "    meta_feats = pd.DataFrame(columns = [col for col in predsTE.keys()])\n",
    "    for model in predsTE.keys():\n",
    "        meta_feats[model] = np.array(predsTE[model])\n",
    "    Xtest = pd.concat([Xtest, meta_feats], axis=1)\n",
    "\n",
    "    # return trainset and testset with metafeatures\n",
    "    return X, Xtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "In the blocks below I will use the stackEnsemble function to create metafeatures for the provided dataset. I will use metafeatures from three simple algorithms: AdaBoost ensemble of decision trees, a Support Vector Classifier and a Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the models\n",
    "model1 = LogisticRegression(C=1e5, class_weight='balanced')\n",
    "model2 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2)\n",
    "                            , n_estimators=300\n",
    "                            , learning_rate=1.5\n",
    "                            , algorithm=\"SAMME\")\n",
    "model3 = SVC(decision_function_shape='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 1 to make predictions..\n",
      "..on split 1\n",
      "..on split 2\n",
      "..on split 3\n",
      "..on split 4\n",
      "..on split 5\n",
      "..on split 6\n",
      "..on split 7\n",
      "..on split 8\n",
      "..on split 9\n",
      "..on split 10\n",
      "Using model 2 to make predictions..\n",
      "..on split 1\n",
      "..on split 2\n",
      "..on split 3\n",
      "..on split 4\n",
      "..on split 5\n",
      "..on split 6\n",
      "..on split 7\n",
      "..on split 8\n",
      "..on split 9\n",
      "..on split 10\n",
      "Using model 3 to make predictions..\n",
      "..on split 1\n",
      "..on split 2\n",
      "..on split 3\n",
      "..on split 4\n",
      "..on split 5\n",
      "..on split 6\n",
      "..on split 7\n",
      "..on split 8\n",
      "..on split 9\n",
      "..on split 10\n"
     ]
    }
   ],
   "source": [
    "models = [model1, model2, model3]\n",
    "X_train_stack, X_test_stack = stackEnsemble(models, X_train, y_train, X_test, 10, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Below I test whether stack ensembling improves classification performance with Logistic Regression. The first example uses the raw dataset; it has no metafeatures. In the second example I use the metafeatures from the models I ensembled with above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.453268641471\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(y_pred=model1.fit(X_train, y_train).predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.560393258427\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(y_pred=model1.fit(X_train_stack, y_train).predict(X_test_stack), y_true=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
