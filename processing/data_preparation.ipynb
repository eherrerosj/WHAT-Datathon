{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Includes data cleaning, feature engineering, dataset merging and train/test ready pickle outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tldextract as tld\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn import datasets\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import *\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date\n",
    "from collections import Counter \n",
    "\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_reduced_train =  pd.read_csv(\"./data/reduced_train.csv\")\n",
    "#df_user_properties = pd.read_csv(\"./data/user_properties.csv\")\n",
    "#df_purchases =  pd.read_csv(\"./data/purchases.csv\")\n",
    "#df_pw_train =  pd.read_csv(\"./data/pw_train.csv\")\n",
    "#df_pw_test =  pd.read_csv(\"./data/pw_test.csv\")\n",
    "df_reduced_test =  pd.read_csv(\"./data/reduced_test.csv\")\n",
    "#df_search_terms_desktop =  pd.read_csv(\"./data/search_terms_desktop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def count_list(field):\n",
    "    number_items = str(field).count(\";\")+1\n",
    "    return number_items\n",
    "\n",
    "def create_feat_eng(df):\n",
    "    df[\"all_domain\"] = df[\"all_domain\"].astype(str)\n",
    "    df[\"total_domains\"] = df.apply(lambda x: count_list(x.all_domain), axis=1)\n",
    "    df[\"total_categories\"] = df.apply(lambda x: count_list(x.all_category), axis=1)\n",
    "\n",
    "    df['day_start'] = df.start.map(lambda x: datetime(int(x.split(\"-\")[0]), int(x.split(\"-\")[1]), int(x.split(\"-\")[2].split(\"T\")[0])).weekday())\n",
    "    df['day_end'] = df.end.map(lambda x: datetime(int(x.split(\"-\")[0]), int(x.split(\"-\")[1]), int(x.split(\"-\")[2].split(\"T\")[0])).weekday())\n",
    "    df['time_start'] = df.start.map(lambda x: int(x.split(\"-\")[2].split(\"T\")[1].split(\"Z\")[0].split(\":\")[0]))\n",
    "    df['time_end'] = df.end.map(lambda x: int(x.split(\"-\")[2].split(\"T\")[1].split(\"Z\")[0].split(\":\")[0]))\n",
    "\n",
    "    df['start_till_weekend'] = df.day_start.map(lambda x: 6 - x)\n",
    "    df['end_till_weekend'] = df.day_end.map(lambda x: 6 - x)\n",
    "\n",
    "    df['date_start'] = df.start.map(lambda x: (int(x.split(\"-\")[2].split(\"T\")[0])))\n",
    "    df['date_end'] = df.end.map(lambda x: (int(x.split(\"-\")[2].split(\"T\")[0])))\n",
    "    df[\"startend\"] = df[\"start\"] + df[\"end\"]\n",
    "    df['duration'] = df.startend.map(lambda x: ((datetime(int(x.split(\"Z\")[1].split(\"-\")[0]),  int(x.split(\"Z\")[1].split(\"-\")[1]), int(x.split(\"Z\")[1].split(\"-\")[2].split(\"T\")[0]), int(x.split(\"Z\")[1].split(\"-\")[2].split(\"T\")[1].split(\":\")[0]), int(x.split(\"Z\")[1].split(\"-\")[2].split(\"T\")[1].split(\":\")[1]), int(x.split(\"Z\")[1].split(\"-\")[2].split(\"T\")[1].split(\":\")[2]))) - (datetime(int(x.split(\"Z\")[0].split(\"-\")[0]),  int(x.split(\"Z\")[0].split(\"-\")[1]), int(x.split(\"Z\")[0].split(\"-\")[2].split(\"T\")[0]), int(x.split(\"Z\")[0].split(\"-\")[2].split(\"T\")[1].split(\":\")[0]), int(x.split(\"Z\")[0].split(\"-\")[2].split(\"T\")[1].split(\":\")[1]), int(x.split(\"Z\")[0].split(\"-\")[2].split(\"T\")[1].split(\":\")[2])))).total_seconds() )\n",
    "    return df\n",
    "\n",
    "df_reduced_train = create_feat_eng(df_reduced_train)\n",
    "df_reduced_train = create_feat_eng(df_reduced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# category list parsing from train set\n",
    "cat_col_tr = []\n",
    "for cat in df_reduced_train['all_category'].values:\n",
    "    tmp = []\n",
    "    try:\n",
    "        for link in cat.split(';'):\n",
    "            tmp.append(link)\n",
    "        cat_col_tr.append(tmp)\n",
    "    except:\n",
    "        cat_col_tr.append([])\n",
    "       \n",
    "\n",
    "cat_col_te = []\n",
    "for cat in df_reduced_test['all_category'].values:\n",
    "    tmp = []\n",
    "    try:\n",
    "        for link in cat.split(';'):\n",
    "            tmp.append(link)\n",
    "        cat_col_te.append(tmp)\n",
    "    except:\n",
    "        cat_col_te.append([])\n",
    "\n",
    "# test category filling \n",
    "# categs = set(list(set([x for y in cat_col_te for x in y if x not in ['']])) + list(set([x for y in cat_col_tr for x in y if x not in ['']]))) \n",
    "# catDF = pd.DataFrame(columns=categs, index=xtmp.session_id.values)\n",
    "# catDF.fillna(0, inplace=True)\n",
    "# catDF = catDF.reset_index()\n",
    "# catDF.rename(columns = {'index':'session_id'}, inplace=True)\n",
    "\n",
    "# for i in tqdm(range(len(cat_col_te))):\n",
    "#     try:\n",
    "#         catDF.loc[i, cat_col_te[i]] = 1\n",
    "#     except:\n",
    "#         continue\n",
    "        \n",
    "# train category filling \n",
    "categs = set(list(set([x for y in cat_col_te for x in y if x not in ['']])) + list(set([x for y in cat_col_tr for x in y if x not in ['']]))) \n",
    "catDF = pd.DataFrame(columns=categs, index=df_reduced_train.session_id.values)\n",
    "catDF.fillna(0, inplace=True)\n",
    "catDF = catDF.reset_index()\n",
    "catDF.rename(columns = {'index':'session_id'}, inplace=True)\n",
    "\n",
    "for i in tqdm(range(len(cat_col_tr))):\n",
    "    try:\n",
    "        catDF.loc[i, cat_col_tr[i]] = 1\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mobile app list parsing from train set\n",
    "app_col_tr = []\n",
    "for app in df_reduced_train['all_app'].values:\n",
    "    tmp = []\n",
    "    try:\n",
    "        for link in app.split(';'):\n",
    "            tmp.append(link)\n",
    "        app_col_tr.append(tmp)\n",
    "    except:\n",
    "        app_col_tr.append([])\n",
    "\n",
    "# mobile app list parsing from test set\n",
    "app_col_te = []\n",
    "for app in df_reduced_test['all_app'].values:\n",
    "    tmp = []\n",
    "    try:\n",
    "        for link in app.split(';'):\n",
    "            tmp.append(link)\n",
    "        app_col_te.append(tmp)\n",
    "    except:\n",
    "        app_col_te.append([])\n",
    "        \n",
    "a =  list([x for y in app_col_te for x in y])\n",
    "\n",
    "letter_counts = Counter(a)\n",
    "dfa = pd.DataFrame(list(letter_counts.items()), columns=['app', 'count'])\n",
    "dfa = dfa[dfa.app != \"\"]\n",
    "dfa = dfa.sort_values('count', ascending=0)\n",
    "dfa = dfa[dfa['count'] > 0]\n",
    "dfa = dfa.app[:300]\n",
    "\n",
    "# test\n",
    "domDF1 = pd.DataFrame(columns=dfa.values, index=df_reduced_train.session_id.values)\n",
    "domDF1.fillna(0, inplace=True)\n",
    "domDF1 = domDF1.reset_index()\n",
    "\n",
    "domDF1.rename(columns = {'index':'session_id'}, inplace=True)\n",
    "\n",
    "for i in tqdm(range(len(app_col_tr))):\n",
    "    try:\n",
    "        domDF1.loc[i,app_col_tr[i]] = 1\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "# test\n",
    "domDF = pd.DataFrame(columns=dfa.values, index=df_reduced_test.session_id.values)\n",
    "domDF.fillna(0, inplace=True)\n",
    "domDF = domDF.reset_index()\n",
    "\n",
    "domDF.rename(columns = {'index':'session_id'}, inplace=True)\n",
    "\n",
    "for i in tqdm(range(len(app_col_te))):\n",
    "    try:\n",
    "        domDF.loc[i,app_col_te[i]] = 1\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_reduced_train = pd.merge(df_reduced_train, catDF, on=\"session_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# generate top domains. load next block instead if data is ready\n",
    "def get_domain(x):\n",
    "    return tld.extract(x)[1]\n",
    "\n",
    "domain_col_te = []\n",
    "for domains in df_reduced_test['all_domain'].values:\n",
    "    tmp = []\n",
    "    try:\n",
    "        for link in domains.split(';'):\n",
    "            tmp.append(get_domain(link))\n",
    "        domain_col_te.append(tmp)\n",
    "    except:\n",
    "        domain_col_te.append([])\n",
    "        \n",
    "a =  list([x for y in domain_col_te for x in y])\n",
    "letter_counts = Counter(a)\n",
    "dfa = pd.DataFrame(list(letter_counts.items()), columns=['domain', 'count'])\n",
    "dfa = dfa[dfa.domain != \"\"]\n",
    "dfa = dfa.sort_values('count', ascending=0)\n",
    "dfa = dfa[dfa['count'] > 10]\n",
    "top = dfa['domain'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "top = pd.read_csv(\"./top500.csv\", header=None)\n",
    "top = list(top.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_durations(picklepath_durations):\n",
    "    durations = pd.read_pickle(picklepath_durations)\n",
    "    # keep only domain durations from the top domain list\n",
    "    durations = durations[durations['domain'].isin(top)]\n",
    "    # chunking due to sparsity, avoid mem issues\n",
    "    res = pd.DataFrame()\n",
    "    for end_chunk in range(100000,durations.shape[0]+1,100000):\n",
    "        print(end_chunk)\n",
    "        res1 = durations.iloc[end_chunk-100000:end_chunk,:].reset_index(drop=False)\\\n",
    "            .pivot_table(values='domain_duration', index=['index', 'session_id'], columns='domain')\n",
    "        try:\n",
    "            res2 = res1.reset_index(drop=False).set_index(\"session_id\").groupby(level=0).sum().drop(\"index\", axis=1)\n",
    "            display(res2.head())\n",
    "        except:\n",
    "            # bypass pandas bug\n",
    "            display(res1.head())\n",
    "            res1.index = res1.index.droplevel(0)\n",
    "            res2 = res1.groupby(level=0).sum().drop(\"index\", axis=1)  \n",
    "        res = res.append(res2)\n",
    "    res = res.groupby(level=0).sum()\n",
    "    res = res.reset_index().rename(columns={\"index\": \"session_id\"})\n",
    "    res[\"session_id\"] = res[\"session_id\"].astype(int)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res = calculate_durations(\"./data/durations.pkl\")\n",
    "df = pd.merge(df_reduced_train, res, on=\"session_id\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "df = pd.get_dummies(df, columns=[\"day_start\", \"day_end\", \"device_session\"])\n",
    "y = df[\"geslacht\"].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.drop([\"panelist_id\",\"all_domain\", \"all_app\", \"all_category\", \"start\", \"end\",\n",
    "         \"startend\", \"session_id\", \"geslacht\"], axis=1, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(df, \"X_train_.pkl\")\n",
    "pd.to_pickle(y, \"y_train_.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**test set prep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# generate test categories\n",
    "cat_col_tr = []\n",
    "for cat in df_reduced_train['all_category'].values:\n",
    "    tmp = []\n",
    "    try:\n",
    "        for link in cat.split(';'):\n",
    "            tmp.append(link)\n",
    "        cat_col_tr.append(tmp)\n",
    "    except:\n",
    "        cat_col_tr.append([])\n",
    "       \n",
    "\n",
    "cat_col_te = []\n",
    "for cat in df_reduced_test['all_category'].values:\n",
    "    tmp = []\n",
    "    try:\n",
    "        for link in cat.split(';'):\n",
    "            tmp.append(link)\n",
    "        cat_col_te.append(tmp)\n",
    "    except:\n",
    "        cat_col_te.append([])\n",
    "\n",
    "# test\n",
    "categs = set(list(set([x for y in cat_col_te for x in y if x not in ['']])) + list(set([x for y in cat_col_tr for x in y if x not in ['']]))) \n",
    "catDF = pd.DataFrame(columns=categs, index=df_reduced_test.session_id.values)\n",
    "catDF.fillna(0, inplace=True)\n",
    "catDF = catDF.reset_index()\n",
    "catDF.rename(columns = {'index':'session_id'}, inplace=True)\n",
    "\n",
    "for i in tqdm(range(len(cat_col_te))):\n",
    "    try:\n",
    "        catDF.loc[i, cat_col_te[i]] = 1\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "# # train\n",
    "# categs = set(list(set([x for y in cat_col_te for x in y if x not in ['']])) + list(set([x for y in cat_col_tr for x in y if x not in ['']]))) \n",
    "# catDF = pd.DataFrame(columns=categs, index=df_reduced_train.session_id.values)\n",
    "# catDF.fillna(0, inplace=True)\n",
    "# catDF = catDF.reset_index()\n",
    "# catDF.rename(columns = {'index':'session_id'}, inplace=True)\n",
    "\n",
    "# for i in tqdm(range(len(cat_col_tr))):\n",
    "#     try:\n",
    "#         catDF.loc[i, cat_col_tr[i]] = 1\n",
    "#     except:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_reduced_test = pd.merge(df_reduced_test, catDF, on=\"session_id\")\n",
    "df_reduced_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res = calculate_durations(\"./data/durations.pkl\")\n",
    "df = pd.merge(df_reduced_test, res, on=\"session_id\", how=\"outer\") # join domain durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# replace nans with zeroes, OHE categoricals, drop non-relevant features for training\n",
    "df.fillna(0, inplace=True)\n",
    "df = pd.get_dummies(df, columns=[\"day_start\", \"day_end\", \"device_session\"])\n",
    "df.drop([\"all_domain\", \"all_app\", \"all_category\", \"start\", \"end\",\n",
    "         \"startend\", \"session_id\"], axis=1, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(df, \"X_test_.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
