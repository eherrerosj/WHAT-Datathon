{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hyperopt example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    t = params['type']\n",
    "    del params['type']\n",
    "    if t == 'naive_bayes':\n",
    "        clf = BernoulliNB(**params)\n",
    "    elif t == 'svm':\n",
    "        clf = SVC(**params)\n",
    "    elif t == 'GradientBoostingClassifier':\n",
    "        clf = GradientBoostingClassifier(**params)\n",
    "    elif t == 'dtree':\n",
    "        clf = DecisionTreeClassifier(**params)\n",
    "    elif t == 'knn':\n",
    "        clf = KNeighborsClassifier(**params)\n",
    "    else:\n",
    "        return 0\n",
    "    return cross_val_score(clf, X, y).mean()\n",
    "\n",
    "space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'naive_bayes',\n",
    "        'alpha': hp.uniform('alpha', 0.0, 2.0)\n",
    "    },\n",
    "    {\n",
    "        'type': 'svm',\n",
    "        'C': hp.uniform('C', 0, 10.0),\n",
    "        'kernel': hp.choice('kernel', ['linear', 'rbf']),\n",
    "        'gamma': hp.uniform('gamma', 0, 20.0)\n",
    "    },\n",
    "    { #tpot best: GradientBoostingClassifier__learning_rate=DEFAULT, GradientBoostingClassifier__max_depth=4,\n",
    "      # GradientBoostingClassifier__max_features=0.3, GradientBoostingClassifier__min_samples_leaf=12,\n",
    "      # GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=DEFAULT,\n",
    "      # GradientBoostingClassifier__subsample=0.45)\n",
    "        'type': 'GradientBoostingClassifier',\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.1, 3.0),\n",
    "        'max_depth': hp.choice('max_depth', range(1,10)),\n",
    "        'max_features': hp.uniform('max_features', 0.1,1.0),\n",
    "        'min_samples_leaf': hp.choice('min_samples_leaf', range(1,30)),\n",
    "        'min_samples_split': hp.choice('min_samples_split', range(2,30)),\n",
    "        'n_estimators': hp.choice('n_estimators', range(10,200)),\n",
    "        'subsample': hp.uniform('subsample', 0.1, 1.0),\n",
    "    },\n",
    "    {\n",
    "        'type': 'randomforest',\n",
    "        'max_depth': hp.choice('_max_depth', range(1,20)),\n",
    "        'max_features': hp.choice('_max_features', range(1,5)),\n",
    "        'n_estimators': hp.choice('_n_estimators', range(1,20)),\n",
    "        'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "        'scale': hp.choice('scale', [0, 1]),\n",
    "        'normalize': hp.choice('normalize', [0, 1])\n",
    "    },\n",
    "    {\n",
    "        'type': 'knn',\n",
    "        'n_neighbors': hp.choice('knn_n_neighbors', range(1,50))\n",
    "    }\n",
    "])\n",
    "\n",
    "'''\n",
    "space = hp.choice('classifier_type', [\n",
    "    { #tpot best: GradientBoostingClassifier__learning_rate=DEFAULT, GradientBoostingClassifier__max_depth=4,\n",
    "      # GradientBoostingClassifier__max_features=0.3, GradientBoostingClassifier__min_samples_leaf=12,\n",
    "      # GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=DEFAULT,\n",
    "      # GradientBoostingClassifier__subsample=0.45)\n",
    "        'type': 'GradientBoostingClassifier',\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.1, 3.0),\n",
    "        'max_depth': hp.choice('max_depth', range(1,10)),\n",
    "        'max_features': hp.uniform('max_features', 0.1,1.0),\n",
    "        'min_samples_leaf': hp.choice('min_samples_leaf', range(1,30)),\n",
    "        'min_samples_split': hp.choice('min_samples_split', range(2,30)),\n",
    "        'n_estimators': hp.choice('n_estimators', range(10,200)),\n",
    "        'subsample': hp.uniform('subsample', 0.1, 1.0),\n",
    "    }\n",
    "])\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "best = 0\n",
    "def f(params):\n",
    "    global best, count\n",
    "    count += 1\n",
    "    acc = hyperopt_train_test(params.copy())\n",
    "    if acc > best:\n",
    "        print 'new best:', acc, 'using', params['type']\n",
    "        best = acc\n",
    "    if count % 50 == 0:\n",
    "        print 'iters:', count, ', acc:', acc, 'using', params\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, space, algo=tpe.suggest, max_evals=3500, trials=trials, verbose=3)\n",
    "print 'best:'\n",
    "print best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*tpot example*. Genetic algo search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.75, test_size=0.25)\n",
    "\n",
    "tpot = TPOTClassifier(population_size=3, verbosity=3, cv=2, generations=3)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_mnist_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "let's try to optimize gradient boosting classifier with hyperopt. Hopefully we will obtain same parameters that tpot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "mlxtend simple stacker with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    "\n",
    "\n",
    "# Initializing models\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = GradientBoostingClassifier(max_depth=4, max_features=0.3, min_samples_leaf=12, min_samples_split=19, subsample=0.45)\n",
    "clf5 = ExtraTreesClassifier(criterion=\"entropy\", max_features=0.35)\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4, clf5], \n",
    "                          meta_classifier=lr, use_probas=True, use_features_in_secondary=True)\n",
    "\n",
    "params = {'kneighborsclassifier__n_neighbors': [1, 5],\n",
    "          'randomforestclassifier__n_estimators': [10, 50],\n",
    "          'gradientboostingclassifier__max_depth': [4, 5],\n",
    "          'gradientboostingclassifier__max_features': [0.3, 0.5],\n",
    "          'gradientboostingclassifier__min_samples_leaf': [12, 20],\n",
    "          'meta-logisticregression__C': [0.1, 10.0],\n",
    "          'meta-logisticregression__dual': [True, False]}\n",
    "\n",
    "grid = GridSearchCV(estimator=sclf, \n",
    "                    param_grid=params, \n",
    "                    cv=5,\n",
    "                    refit=True)\n",
    "grid.fit(X, y)\n",
    "\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.4f' % grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!cat tpot_mnist_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "gcForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from GCForest import gcForest\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.33)\n",
    "gcf = gcForest(shape_1X=4, window=2, tolerance=0.0)\n",
    "gcf.fit(X_tr, y_tr)\n",
    "pred_X = gcf.predict(X_te)\n",
    "print(pred_X)\n",
    "accuracy = accuracy_score(y_true=y_te, y_pred=pred_X)\n",
    "print('gcForest accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gcf = gcForest(shape_1X=[8,8], window=[4,6], tolerance=0.0, min_samples_mgs=10, min_samples_cascade=7)\n",
    "gcf.fit(X_tr, y_tr)\n",
    "pred_X = gcf.predict(X_te)\n",
    "print(pred_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true=y_te, y_pred=pred_X)\n",
    "print('gcForest accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
