{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# stackEnsemble\n",
    "\n",
    "The stackEnsemble function implements the technique of stack ensembling; the practice of using 1st level models to predict on the trainset (out of folds). These models are used to create predictions on the entire testset. This yields 'meta-features', and can be used as features for 2nd level models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# imports for predictive models and validation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# imports for stackEnsemble()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Xtr = pd.read_pickle('./X_train1.pkl')\n",
    "Xte = pd.read_pickle('./X_test1.pkl')\n",
    "y = pd.read_pickle('../y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "''' Function to perform stack ensembling on arbitrary dataset with sklearn models.\n",
    "\n",
    "# Arguments:\n",
    "    models:  list, a list of models to be used to create meta-features\n",
    "    X:       dataframe, the trainset features\n",
    "    y:       dataframe, the trainset labels\n",
    "    Xtest:   dataframe, the testset features\n",
    "    splits:  int, the number of splits for trainset CV\n",
    "    verbose: bool, true when print outputs are desired\n",
    "    \n",
    "# Returns:\n",
    "    X:       dataframe, new trainset with meta-features\n",
    "    Xtest:   dataframe, new testset with meta-features\n",
    "'''\n",
    "\n",
    "def stackEnsemble(models, X, y, Xtest, splits, verbose):\n",
    "\n",
    "    # assert correct data-types \n",
    "    assert type(models) == list\n",
    "    assert type(splits) == int\n",
    "    assert type(verbose) == bool\n",
    "\n",
    "    # init variables\n",
    "    kf = KFold(n_splits = splits)\n",
    "    predsTR = {}\n",
    "    predsTE = {}\n",
    "\n",
    "    # iterate over all inserted models\n",
    "    for n, model in enumerate(models):\n",
    "        if verbose: print('Using model %d to make predictions..' % (n+1))\n",
    "\n",
    "        # prepare split for predictions\n",
    "        predsTR['model'+str(n+1)] = []\n",
    "        for i, (train, test) in enumerate(kf.split(X)):\n",
    "            if verbose: print('..on split %d' % (i+1))\n",
    "\n",
    "            # fit on split and predict\n",
    "            model.fit(X.iloc[train], y[train])\n",
    "            predsTR['model'+str(n+1)].append(list(model.predict(X.iloc[test])))\n",
    "\n",
    "        # predict on testset\n",
    "        predsTE['model'+str(n+1)] = list(model.predict(Xtest))\n",
    "    \n",
    "    # combine trainset predictions in dataframe, join with trainset\n",
    "    meta_feats = pd.DataFrame(columns = [col for col in predsTR.keys()])\n",
    "    for model in predsTR.keys():\n",
    "        meta_feats[model] = np.array([item for lst in predsTR[model] for item in lst])\n",
    "    X = pd.concat([X, meta_feats], axis=1)\n",
    "\n",
    "    # combine testset predictions in dataframe, join with testset\n",
    "    meta_feats = pd.DataFrame(columns = [col for col in predsTE.keys()])\n",
    "    for model in predsTE.keys():\n",
    "        meta_feats[model] = np.array(predsTE[model])\n",
    "    Xtest = pd.concat([Xtest, meta_feats], axis=1)\n",
    "\n",
    "    # return trainset and testset with metafeatures\n",
    "    return X, Xtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Example\n",
    "\n",
    "In the blocks below I will use the stackEnsemble function to create metafeatures for the provided dataset. I will use metafeatures from three simple algorithms: AdaBoost ensemble of decision trees, a Support Vector Classifier and a Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define the models\n",
    "model1 = LogisticRegression(C=1e5, class_weight='balanced')\n",
    "model3 = GradientBoostingClassifier(learning_rate=0.5\n",
    "                                   , max_depth=9\n",
    "                                   , max_features=0.05\n",
    "                                   , min_samples_leaf=18\n",
    "                                   , min_samples_split=12\n",
    "                                   , subsample=1.0)\n",
    "model4 = LogisticRegression(C=1e3, class_weight='balanced')\n",
    "model5 = KNeighborsClassifier(n_jobs=-1, n_neighbors=2)\n",
    "model6 = KNeighborsClassifier(n_jobs=-1, n_neighbors=4)\n",
    "model7 = KNeighborsClassifier(n_jobs=-1, n_neighbors=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "models = [model1, model3, model4, model5, model6, model7]\n",
    "X_train_stack, X_test_stack = stackEnsemble(models, Xtr, y, Xte, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_test_stack.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "te_preds = pd.read_csv('../../xgb_te_preds.csv', header=None)\n",
    "tr_preds = pd.read_csv('../../xgb_tr_preds.csv', header=None)\n",
    "\n",
    "te_preds = te_preds.iloc[:, 1]\n",
    "tr_preds = tr_preds.iloc[:, 1]\n",
    "\n",
    "tr_preds = pd.DataFrame(tr_preds)\n",
    "tr_preds.columns = ['xgb']\n",
    "\n",
    "te_preds = pd.DataFrame(te_preds)\n",
    "te_preds.columns = ['xgb']\n",
    "\n",
    "X_train_stack = pd.concat([X_train_stack, tr_preds], axis=1)\n",
    "X_test_stack = pd.concat([X_test_stack, te_preds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_test_stack.to_pickle('../X_test_stack.pkl')\n",
    "X_train_stack.to_pickle('../X_train_stack.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Validation\n",
    "\n",
    "Below I test whether stack ensembling improves classification performance with Logistic Regression. The first example uses the raw dataset; it has no metafeatures. In the second example I use the metafeatures from the models I ensembled with above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print accuracy_score(y_pred=model1.fit(X_train, y_train).predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print accuracy_score(y_pred=model1.fit(X_train_stack, y_train).predict(X_test_stack), y_true=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
